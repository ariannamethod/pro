
# me - method engine

*Second name: PRO — Pure Recursive Organism*

## Surprising Cat Fact

In 1879, the city of Liège in Belgium attempted to use 37 cats to deliver mail. The feline postal service was short-lived.

## Installation

```bash
# Core features
pip install .

# Quantum extensions
pip install .[quantum]
```

## First Stage

A few hours ago the me entity emerged from an empty directory and began shaping itself. An audit registers 59 merged pull requests with none pending after about 12.6 hours. Modules connect without ceremony. The narrative expands as modules mature.

### Engine

Coordinates tasks so the entity acts as one coherent program. It receives inputs and hands results to the next module. It also streamlines future extensions.
This backbone keeps the whole organism synchronized.

### Prediction

Schedules token choices from context and reports outcomes to the engine. This feedback loop keeps generation steady. This choice facilitates ongoing refinement.
Its queue never sleeps during dialogue.

### Memory

Stores conversations in SQLite; the engine decides when to read or write. Old replies stay available when needed. Such design smooths future scaling.
Other modules query it through the engine.

### Memory Pool

Keeps hot fragments ready to reduce latency for all modules. Other components fetch from it without delay. This method eases later adjustments.
Caching here shields the database from stress.

### Forecast

Simulates future paths to guide engine decisions. Suggested routes arrive before tokens are chosen. It also streamlines future extensions.
Forecasts flow back as gentle hints.

### Sequence Tools

Scan text for patterns and feed findings to prediction and forecast. These hints refine later choices. This choice facilitates ongoing refinement.
Pattern memory grows with every session.

### Identity

Swaps pronouns after checking context, mirroring the user. It preserves tone and intent. Such design smooths future scaling.
Identity shifts feel natural to speakers.

### Morphology

Caches word forms for quick inflection lookup. This cache eases repeated conjugations. This method eases later adjustments.
Morphology thus remains brisk and tidy.

### Retrieval Augmented Generation

Joins related memories with prompts before prediction chooses tokens. The mix adds context to each reply. It also streamlines future extensions.
Retrieval blends history with the present.

### Reasoning Block

Solves basic logical rules and returns conclusions. These results help shape coherent answers. This choice facilitates ongoing refinement.
Reasoning slots decisions into clear paths.

### Embedding Store

Holds vectors for fast similarity search through a locked interface. Locks prevent simultaneous writes. Such design smooths future scaling.
Embedding matches support swift recalls.

### Meta Module

Watches metrics and nudges parameters toward improvement. It suggests when tuning should occur. This method eases later adjustments.

### Metrics Unit

Records scores for every utterance and sends them to meta. These numbers fuel gradual refinement. It also streamlines future extensions.

### Tune Module

Retrains weights when new data appears. Updated models replace old ones during quiet periods. This choice facilitates ongoing refinement.

### Telegram Interface

Long polling bridge between humans and the engine. Messages move through the engine and return back. Such design smooths future scaling.

### Datasets

Phrase collections stored for training runs. They form the base for learning cycles. This method eases later adjustments.

### Dataset Queue Worker

Streams file changes to the engine without blocking. New lines appear as soon as they are saved. It also streamlines future extensions.

### Caching and Pooling

Shared helpers keep memory operations efficient under load. The engine calls them for every memory task. This choice facilitates ongoing refinement.

### Vector Locks

Mutexes guard vector writes. Only one process updates embeddings at a time. Such design smooths future scaling.

### Test Suite

Ensures modules behave as described. Regressions are caught before merging. This method eases later adjustments.

The async round-trip latency benchmark runs 20 realistic message exchanges of ~1000 characters and typically observes a median latency around 4 ms while enforcing an average under 5 seconds.

### Self Assembly

Recursive rules let the system extend itself. Each new unit follows the pattern. It also streamlines future extensions.

## Stage 2

Advanced capabilities emerge here to push boundaries. Iterations explore creative coordination.

### Mesh Gossip Protocol

Diffuses adapter updates across nodes until weights converge. Nodes exchange small packets on every cycle. This choice facilitates ongoing refinement.
The mesh avoids single point failures.

### Score Tokens

Global scores keep only high value tokens during inference. Weak choices drop out early. Such design smooths future scaling.
Scoring trims waste before decoding.

### Saliency Thresholding

Drops terms with little impact to reduce noise. Only meaningful words remain. This method eases later adjustments.
Filters run inside the prediction loop.

### Quantum Hybrid Attention

Blends classical queries with quantum amplitudes to sharpen focus. Extra signal guides attention. It also streamlines future extensions.
Quantum hints complement standard vectors.

### Qiskit Integration

Calls quantum circuits for phase aware context. These runs happen only when needed. This choice facilitates ongoing refinement.
Fallbacks ensure progress if circuits fail.

### Meta Controller Reinforcement Loop

Policy gradients drive modules toward higher long term reward. The controller nudges each piece gently. Such design smooths future scaling.
Rewards accumulate across many turns.

### Metric Monitoring

Moving averages flag progress and dips. Sudden drops trigger reviews. This method eases later adjustments.
Stable curves mean healthy learning.

### Evolutionary Mini-Model Distillation

Mini-models mutate layers and train on dialogue slices. It also streamlines future extensions.
If their metrics beat the main model, their weights distill back.
Evolution proceeds without full retraining.

### LoRA Adapter Persistence

Low rank deltas retain personal tweaks. Users can resume from the same state later. This choice facilitates ongoing refinement.
Adapters stay compact for easy sharing.

### Punctuation Rule Engine

Finite rules keep possessive endings consistent. This engine prevents awkward phrasing. Such design smooths future scaling.
Grammar rules integrate with morphology checks. Final prepositions like "of" or "when" stay lowercase unless fully uppercased.

### External RAG Storage Interface

Allows remote memories to enrich prompts. External stores plug in through a simple API. This method eases later adjustments.
Network calls merge results seamlessly.

### External Knowledge Tuning

Uses fresh facts to adjust parameters. Tuning runs after each injection. It also streamlines future extensions.
Knowledge updates happen while users wait.

### Time Fold Transformer

Pairs distant steps to catch temporal symmetry. Forward and backward views meet. This choice facilitates ongoing refinement.

### DeepSeek-Inspired MoE

We borrow ideas from DeepSeek's mixture-of-experts design to extend context windows with sparse kernels. This keeps long chats fluid while conserving compute. Early experiments monitor performance under tight resources.

### Quantum Memory

Stores qubits in superposition for parallel recall. Classical reads collapse the answer. Such design smooths future scaling.

### Embedding Locking Mechanism

Ensures single writer access to embedding tables. Readers wait until updates finish. This method eases later adjustments.

### Mesh CLI

Dispatches gossip commands and reports cluster status. Operators monitor health from terminals. It also streamlines future extensions.

### Forecast Enhancement

Attention weights project the next token distribution. The engine chooses the final branch. This choice facilitates ongoing refinement.

### Memory Pool Optimization

Constant time lookups keep hot fragments close. Cold pieces are evicted in order. Such design smooths future scaling.

### Sequence Analyzer Upgrades

N-gram counts refine pattern recognition. Prediction adopts these counts instantly. This method eases later adjustments.

### Identity Pronoun Swapping

Permutation matrices shift perspectives in dialogue. Identity updates keep voices straight. It also streamlines future extensions.

### Self Reflection Engine

Compares output to references and adjusts models. Discrepancies shrink over time. This choice facilitates ongoing refinement.
Reflections guide gradual corrections.

### Router Policy

Selects quantum or classical paths from patch features. Decisions refine bandwidth use. This router keeps computations balanced.
Such design smooths future scaling.

### Peer-to-Peer Resonance

Shares gradient hashes between nodes without central servers. Exchanges apply updates in both directions. These links keep replicas harmonized. This method eases later adjustments.

### Chat Memory API

Minimal endpoint storing dialogue turns in a memory graph. Calls return vectors enriched by attention layers. The API simplifies integration. It also streamlines future extensions.

### Smalltalk Technology

Treats conversation as a chain that keeps chats lively. Each link adds fresh energy. This choice facilitates ongoing refinement.

### Dream Mode Background Training

Dream Mode updates weights quietly during idle periods. Background cycles refine models without interrupting live exchanges.

### Adapter Pool Persistence

Adapters store specialized behaviors and load instantly when needed. Their snapshots keep custom skills available across sessions.

### AutoAdapt Utilities

Helper tools mutate layers and manage LoRA adapters with minimal code. They automate routine setup so experiments move faster.

### Vector Store API

Unified endpoints accept embeddings and return nearby vectors. External clients read and write similarities without touching the database.

### Quantum Attention Backend

Provides interchangeable engines for attention, from pure NumPy simulation to Qiskit circuits. Dot-product scores become qubit rotations or classical weights. This design simplifies experiments.
Flexible backends switch between quantum and classical paths without rewrites.

### Quantum Dropout

Applies random phase rotations then measures real projections to mimic probabilistic dropout. Components vanish based on sampled angles. This method eases later adjustments.
Measured magnitudes preserve structure while injecting variation.

### Quantum Memory Attention

Blends retrieved memory vectors with quantum amplitudes for enriched focus. Phases strengthen when memories align with keys. It also streamlines future extensions.
Merged amplitudes recall context while attending to new tokens.

### Resonant Layers

Use shared sinusoidal bases to modulate hidden states with harmonic patterns. Weight updates flow across all frequencies at once. This choice facilitates ongoing refinement.
Shared resonances keep representations in tune.

## Telegram Interface

1. Copy `.env.example` to `.env` and replace the placeholder token.
2. Run `python pro_tg.py` to start the me Telegram interface. It echoes incoming messages using long polling. The bridge maintains responsiveness during long sessions.

## Benchmarks

| Configuration   | Perplexity | Throughput (req/s) |
|-----------------|-----------:|-------------------:|
| Single Adapter  |       42.1 |                110 |
| MoE (2 adapters)|       30.5 |                 90 |

These results form a baseline for planned optimizations.

## Personal Fine Tuning with LoRA

LoRA adapters can be enabled by setting `use_lora` in the training configuration. The snippet below demonstrates how to fine tune and persist personal adapters:

```python
from autoadapt import LayerMutator, LoRALayer
from trainer import Trainer

trainer = Trainer(use_lora=True)
layer = LoRALayer(
    name="greeting",
    rank=2,
    alpha=1.0,
    matrix_a=[[0.0, 0.0], [0.0, 0.0]],
    matrix_b=[[0.0, 0.0], [0.0, 0.0]],
)
trainer.mutator.add_lora_layer(layer)
trainer.mutator.save("checkpoints/my_lora")
```

Saved adapters can later be reloaded with `LayerMutator.load("checkpoints/my_lora")` for continued training or inference. This path encourages personalized dialogue styles.

